# The number of attention heads in each multi-head attention block
NUM_ATTN_HEADS = 3
# The number of transformer blocks
NUM_BLOCKS = 3
# Drop 10%
DROPOUT_PROB = 0.1
# The width of the embedding vectors
EMBED_DIM = 48
